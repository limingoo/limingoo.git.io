<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>WuHainan&#39;Blog</title>
  
  <subtitle>记录自学CS的每一步</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://wuhainan.com/"/>
  <updated>2018-11-19T01:10:09.112Z</updated>
  <id>http://wuhainan.com/</id>
  
  <author>
    <name>天道酬勤whn</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>求解Ax=0</title>
    <link href="http://wuhainan.com/2018/11/19/%E6%B1%82%E8%A7%A3Ax=0/"/>
    <id>http://wuhainan.com/2018/11/19/求解Ax=0/</id>
    <published>2018-11-19T01:10:09.000Z</published>
    <updated>2018-11-19T01:10:09.112Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>向量空间、列空间和零空间</title>
    <link href="http://wuhainan.com/2018/11/18/%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4%E3%80%81%E5%88%97%E7%A9%BA%E9%97%B4%E5%92%8C%E9%9B%B6%E7%A9%BA%E9%97%B4/"/>
    <id>http://wuhainan.com/2018/11/18/向量空间、列空间和零空间/</id>
    <published>2018-11-18T11:13:39.000Z</published>
    <updated>2018-11-19T01:02:46.130Z</updated>
    
    <content type="html"><![CDATA[<h1 id="向量空间"><a href="#向量空间" class="headerlink" title="向量空间"></a>向量空间</h1><p>①所有向量空间都必须包含零向量，即包含原点。</p><p>②向量空间中任意向量的数乘、求和运算得到的向量也在该空间中，即向量空间要满足加法封闭和数乘封闭。</p><p>③向量空间$R^n$包含所有的n维向量，分量均为实数。</p><h1 id="子空间"><a href="#子空间" class="headerlink" title="子空间"></a>子空间</h1><p>向量空间的子空间也必须满足加法封闭和数乘封闭，并且也包含零向量。</p><p>$R^2$的子空间：①$R^2本身$；②过原点的直线；③零向量(即原点)；</p><p>$R^3$的子空间：①$R^3本身$；②过原点的平面；③过原点的直线；④零向量。</p><h1 id="列空间"><a href="#列空间" class="headerlink" title="列空间"></a>列空间</h1><p>设$A=\begin{bmatrix}1&amp;3\\2&amp;3\\4&amp;1\end{bmatrix}$，其中各列属于$R^3$，那么所有列的所有线性组合构成$R^3$的一个子空间，在这里为过原点的一个平面，称该子空间为$A$的列空间，记作$C(A)$。如果$A$的两列共线，则列空间为一条直线。</p><p>构造矩阵列空间的方法：取出各列，然后线性组合，则所有的线性组合构成列空间。</p><p>假设$P$为三维空间中过原点的平面，$L$为过原点的直线($L$不在$P$内)，$P、L$都为子空间，而$P∪L$不是子空间，因为加法不封闭，$P∩L$是子空间，因为只含零向量。一般情况下，若$S、T$均为子空间，则$S∩T$也为子空间。</p><p>$Ax=b$并不是对任意的$b$都有解，只有$b$属于$A$的列空间时才有解。例如：</p><script type="math/tex; mode=display">Ax=\begin{bmatrix}1&1&2\\2&1&3\\3&1&4\\4&1&5\end{bmatrix}\begin{bmatrix}x_1\\x_2\\x_3\end{bmatrix}=\begin{bmatrix}b_1\\b_2\\b_3\\b_4\end{bmatrix}</script><p>$A$的三个列向量的线性组合无法充满整个四维空间，所以可能有些$b$不是这三个列向量的线性组合。</p><p>在$A$中，其实第三列可以去掉，是前两列的线性组合，对结果没有影响。</p><h1 id="零空间"><a href="#零空间" class="headerlink" title="零空间"></a>零空间</h1><p>$A$的零空间为$Ax=0$中所有的解$x$组成的集合，记作$N(A)$。不管$A$是什么矩阵，其零空间必然含有零向量。例如：</p><script type="math/tex; mode=display">Ax=\begin{bmatrix}1&1&2\\2&1&3\\3&1&4\\4&1&5\end{bmatrix}\begin{bmatrix}x_1\\x_2\\x_3\end{bmatrix}=\begin{bmatrix}0\\0\\0\\0\end{bmatrix}</script><p>$\begin{bmatrix}0\\0\\0\end{bmatrix}、\begin{bmatrix}1\\1 \\ -1\end{bmatrix}\cdots\begin{bmatrix}c\\c \\ -c\end{bmatrix}$，即$c\begin{bmatrix}1\\1 \\ -1\end{bmatrix}$为$A$的零空间，为三维空间中过原点的直线。</p><p>验证：$A$的零空间为子空间。</p><p>证明如下：①如果$Ax=0并且Ay=0$，那么$A(ax+by)=aAx+bAy=0$，也就是说$v$和$w$都在零空间，那么其和$v$和$w$的线性组合也在零空间内。②如果$Av=0$，那么$A(av)=aAv=0$，即如果$v$在零空间，那么其数乘$av$也在零空间内。综上所述，零空间满足加法和数乘封闭，并且包含零向量，所以为子空间。</p><p>如果$Ax=\begin{bmatrix}1&amp;1&amp;2\\2&amp;1&amp;3\\3&amp;1&amp;4\\4&amp;1&amp;5\end{bmatrix}\begin{bmatrix}x_1\\x_2\\x_3\end{bmatrix}=\begin{bmatrix}1\\2\\3\\4\end{bmatrix}$，其所有的解构成子空间吗？</p><p>答案是否定的，因为解中不包含零向量，这里的解其实为三维空间中不过原点的直线。</p><p>构造子空间的两种方法：</p><p>①取各列的线性组合；</p><p>②从方程组中通过让$x$满足特定条件来得到子空间。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;向量空间&quot;&gt;&lt;a href=&quot;#向量空间&quot; class=&quot;headerlink&quot; title=&quot;向量空间&quot;&gt;&lt;/a&gt;向量空间&lt;/h1&gt;&lt;p&gt;①所有向量空间都必须包含零向量，即包含原点。&lt;/p&gt;
&lt;p&gt;②向量空间中任意向量的数乘、求和运算得到的向量也在该空间中，即向
      
    
    </summary>
    
      <category term="线性代数" scheme="http://wuhainan.com/categories/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
    
      <category term="线性代数" scheme="http://wuhainan.com/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>转置与置换</title>
    <link href="http://wuhainan.com/2018/11/16/%E8%BD%AC%E7%BD%AE%E4%B8%8E%E7%BD%AE%E6%8D%A2/"/>
    <id>http://wuhainan.com/2018/11/16/转置与置换/</id>
    <published>2018-11-16T05:47:35.000Z</published>
    <updated>2018-11-18T11:08:53.370Z</updated>
    
    <content type="html"><![CDATA[<h1 id="转置"><a href="#转置" class="headerlink" title="转置"></a>转置</h1><p>设$A=\begin{bmatrix}1&amp;2&amp;4\\3&amp;3&amp;1\end{bmatrix}$，则$A^T=\begin{bmatrix}1&amp;3\\2&amp;3\\4&amp;1\end{bmatrix}$，即$(A^T)_{ij}=A_{ji}$，$A^TA=\begin{bmatrix}10&amp;11&amp;7\\11&amp;13&amp;11\\7&amp;11&amp;17\end{bmatrix}$，对于所有的矩阵$A$，$A^TA$都是对称的，对于对称矩阵，其转置等于其本身。</p><p>$AA^{-1}=I$，两边同时转置得，$(A^{-1})^TA^T=I$，所以有$(A^T)^{-1}=(A^{-1})^T$</p><h1 id="置换矩阵"><a href="#置换矩阵" class="headerlink" title="置换矩阵"></a>置换矩阵</h1><p>置换矩阵是用来完成行互换的矩阵，记作$P$，即单位矩阵的行重新排列后的矩阵，例如：</p><script type="math/tex; mode=display">互换行一与行二的置换矩阵P_{12}=\begin{bmatrix}0&1&0\\1&0&0\\0&0&1\end{bmatrix}\\互换行一与行三的置换矩阵P_{13}=\begin{bmatrix}0&0&1\\0&1&0\\1&0&0\end{bmatrix}\\互换行二与行三的置换矩阵P_{23}=\begin{bmatrix}1&0&0\\0&0&1\\0&1&0\end{bmatrix}</script><p>上面这两个矩阵都是行互换一次的置换矩阵，如果交换所有的行，可以得到下面的矩阵</p><script type="math/tex; mode=display">\begin{bmatrix}0&1&0\\0&0&1\\1&0&0\end{bmatrix}、\begin{bmatrix}0&0&1\\1&0&0\\0&1&0\end{bmatrix}</script><p>加上单位矩阵$I$本身($I$是不需做任何变换的矩阵，即任何矩阵乘以$I$等于其本身)，如果将这6个矩阵两两相乘，结果仍在这6个矩阵当中，它们的逆也在其中，我们称这6个矩阵构成一个群。</p><p>我们还可以得出一个结论：置换矩阵的逆等于其转置，即$P^{-1}=P^T$，并且所有置换矩阵均可逆。对于$n×n$的矩阵，总共有$n!$种置换矩阵。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;转置&quot;&gt;&lt;a href=&quot;#转置&quot; class=&quot;headerlink&quot; title=&quot;转置&quot;&gt;&lt;/a&gt;转置&lt;/h1&gt;&lt;p&gt;设$A=\begin{bmatrix}1&amp;amp;2&amp;amp;4\\3&amp;amp;3&amp;amp;1\end{bmatrix}$，则$A^T=\b
      
    
    </summary>
    
      <category term="线性代数" scheme="http://wuhainan.com/categories/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
    
      <category term="线性代数" scheme="http://wuhainan.com/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>转置与置换</title>
    <link href="http://wuhainan.com/2018/11/16/A%E7%9A%84LU%E5%88%86%E8%A7%A3/"/>
    <id>http://wuhainan.com/2018/11/16/A的LU分解/</id>
    <published>2018-11-16T05:47:35.000Z</published>
    <updated>2018-11-18T09:27:50.490Z</updated>
    
    <content type="html"><![CDATA[<p>$AA^{-1}=I$，两边同时转置得，$(A^{-1})^TA^T=I$，所以有$(A^T)^{-1}=(A^{-1})^T$</p><h1 id="置换矩阵"><a href="#置换矩阵" class="headerlink" title="置换矩阵"></a>置换矩阵</h1><p>置换矩阵是用来完成行互换的矩阵，记作$P$，即单位矩阵的行重新排列后的矩阵，例如：</p><script type="math/tex; mode=display">互换行一与行二的置换矩阵P_{12}=\begin{bmatrix}0&1&0\\0&1&0\\1&0&0\end{bmatrix}\\互换行一与行三的置换矩阵P_{13}=\begin{bmatrix}0&0&1\\0&1&0\\1&0&0\end{bmatrix}\\互换行二与行三的置换矩阵P_{23}=\begin{bmatrix}1&0&0\\0&0&1\\0&1&0\end{bmatrix}</script><p>上面这两个矩阵都是行互换一次的置换矩阵，如果交换所有的行，可以得到下面的矩阵</p><script type="math/tex; mode=display">\begin{bmatrix}0&1&0\\0&0&1\\1&0&0\end{bmatrix}、\begin{bmatrix}0&0&1\\1&0&0\\0&1&0\end{bmatrix}</script><p>加上单位矩阵$I$本身($I$是不需做任何变换的矩阵，即任何矩阵乘以$I$等于其本身)，如果将这6个矩阵两两相乘，结果仍在这6个矩阵当中，它们的逆也在其中，我们称这6个矩阵构成一个群。</p><p>我们还可以得出一个结论：置换矩阵的逆等于其转置，即$P^{-1}=P^T$</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;$AA^{-1}=I$，两边同时转置得，$(A^{-1})^TA^T=I$，所以有$(A^T)^{-1}=(A^{-1})^T$&lt;/p&gt;
&lt;h1 id=&quot;置换矩阵&quot;&gt;&lt;a href=&quot;#置换矩阵&quot; class=&quot;headerlink&quot; title=&quot;置换矩阵&quot;&gt;&lt;/a&gt;置换
      
    
    </summary>
    
    
      <category term="线性代数" scheme="http://wuhainan.com/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>矩阵乘法和逆</title>
    <link href="http://wuhainan.com/2018/11/14/%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E5%92%8C%E9%80%86/"/>
    <id>http://wuhainan.com/2018/11/14/矩阵乘法和逆/</id>
    <published>2018-11-14T00:44:42.000Z</published>
    <updated>2018-11-14T08:54:50.698Z</updated>
    
    <content type="html"><![CDATA[<h1 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a>矩阵乘法</h1><p>法一：</p><p>假设$A$是$m×n$矩阵，$B$是$n×p$矩阵，$AB=C$，则$c_{ij}=a_{i1}b_{1j}+a_{i2}b_{2j}+\cdots+a_{in}b_{nj}=\sum_{k=1}^na_{ik}b_{kj}$</p><p>法二：</p><p>将乘法考虑为矩阵乘以向量，将$B$看成$p$个单独的列向量，然后用$A$乘以每个列向量，得到$C$中的每一列。</p><p>法三：</p><p>$A$的每一行乘以$B$得到$C$中的每一行，$C$中的各行是$B$中各行的线性组合。</p><p>法四：</p><p>$AB=A$中各列与$B$各行的乘积之和$=$列一×行一+列二×行二+$\cdots$</p><p>如$\begin{bmatrix}2&amp;7\\3&amp;8\\4&amp;9\end{bmatrix}\begin{bmatrix}1&amp;6\\0&amp;0\end{bmatrix}=\begin{bmatrix}2\\3\\4\end{bmatrix}\begin{bmatrix}1&amp;6\end{bmatrix}+\begin{bmatrix}7\\8\\9\end{bmatrix}\begin{bmatrix}0&amp;0\end{bmatrix}=\begin{bmatrix}2&amp;12\\3&amp;18\\4&amp;24\end{bmatrix}$</p><p>法五：</p><p>分块乘法</p><h1 id="矩阵的逆"><a href="#矩阵的逆" class="headerlink" title="矩阵的逆"></a>矩阵的逆</h1><p>首先不是所有的矩阵都存在逆，假设$A$为方阵，并且逆存在，则有</p><script type="math/tex; mode=display">A^{-1}A=AA^{-1}=I</script><p>对于方阵而言，左逆等于右逆，但是如果$A$为非方阵，左逆就不等于右逆。通常我们称不可逆矩阵为奇异矩阵。下面看看不可逆的情况：$A=\begin{bmatrix}1&amp;3\\2&amp;6\end{bmatrix}$</p><p>为什么$A$不可逆呢？首先$A$对应的行列式$|A|=0$，这个可以用于判断$n$阶方阵$A$是否可逆。其次，如果存在非零向量$x$，使$Ax=0$，则$A$不可逆。在这里取$x=\begin{bmatrix}-3\\1\end{bmatrix}$，有</p><script type="math/tex; mode=display">Ax=\begin{bmatrix}1&3\\2&6\end{bmatrix}\begin{bmatrix}-3\\1\end{bmatrix}=\begin{bmatrix}0\\0\end{bmatrix}</script><p>即奇异矩阵的各列通过线性组合能够得到零向量。</p><h2 id="高斯-若尔当消元"><a href="#高斯-若尔当消元" class="headerlink" title="高斯-若尔当消元"></a>高斯-若尔当消元</h2><p>设$A=\begin{bmatrix}1&amp;3\\2&amp;7\end{bmatrix}$，那么如何求$A^{-1}$呢？按照逆的定义，有</p><script type="math/tex; mode=display">\begin{bmatrix}1&3\\2&7\end{bmatrix}\begin{bmatrix}a&c\\b&d\end{bmatrix}=\begin{bmatrix}1&0\\0&1\end{bmatrix}</script><p>按照矩阵乘法，有</p><script type="math/tex; mode=display">\left\{\begin{aligned}\begin{bmatrix}1&3\\2&7\end{bmatrix}\begin{bmatrix}a\\b\end{bmatrix}=\begin{bmatrix}1\\0\end{bmatrix}\\\begin{bmatrix}1&3\\2&7\end{bmatrix}\begin{bmatrix}c\\d\end{bmatrix}=\begin{bmatrix}0\\1\end{bmatrix}\\\end{aligned}\right.</script><p>解此方程组即可。但是该方法比较麻烦，高斯-若尔当(Gauss-Jordan)方法可以一次处理所有的方程。构造这样的方程$\left[\begin{array}{cc|cc}1&amp;3&amp;1&amp;0\\2&amp;7&amp;0&amp;1\end{array}\right]$，左侧为矩阵$A$，右侧为$I$，接下来通过消元法，将左侧变为单位阵，右侧即为$A$的逆矩阵。具体过程如下：</p><script type="math/tex; mode=display">\left[\begin{array}{cc|cc}1&3&1&0\\2&7&0&1\end{array}\right]\underrightarrow{\text{row2-2row1}}\begin{bmatrix}1&3&1&0\\0&1&-2&1\end{bmatrix}\underrightarrow{\text{row1-3row2}}\left[\begin{array}{cc|cc}1&0&7&-3\\0&1&-2&1\end{array}\right]</script><p>所以$A^{-1}=\begin{bmatrix}7&amp;-3 \\ -2&amp;1\end{bmatrix}$</p><p>总结：</p><p>求$A^{-1}$的方法</p><script type="math/tex; mode=display">\begin{bmatrix}A&I\end{bmatrix}\underrightarrow{\text{消元}}\begin{bmatrix}I&A^{-1}\end{bmatrix}</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;矩阵乘法&quot;&gt;&lt;a href=&quot;#矩阵乘法&quot; class=&quot;headerlink&quot; title=&quot;矩阵乘法&quot;&gt;&lt;/a&gt;矩阵乘法&lt;/h1&gt;&lt;p&gt;法一：&lt;/p&gt;
&lt;p&gt;假设$A$是$m×n$矩阵，$B$是$n×p$矩阵，$AB=C$，则$c_{ij}=a_{i1}b_{
      
    
    </summary>
    
      <category term="线性代数" scheme="http://wuhainan.com/categories/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
    
      <category term="线性代数" scheme="http://wuhainan.com/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>矩阵消元</title>
    <link href="http://wuhainan.com/2018/11/13/%E7%9F%A9%E9%98%B5%E6%B6%88%E5%85%83/"/>
    <id>http://wuhainan.com/2018/11/13/矩阵消元/</id>
    <published>2018-11-13T07:57:59.000Z</published>
    <updated>2018-11-14T09:00:35.570Z</updated>
    
    <content type="html"><![CDATA[<h1 id="消元法"><a href="#消元法" class="headerlink" title="消元法"></a>消元法</h1><p>有方程组$\left\{\begin{aligned}x+2y+z=2\\3x+8y+z=12\\4y+z=2\end{aligned}\right.$，写成矩阵形式$Ax=b$为$\begin{bmatrix}1&amp;2&amp;1\\3&amp;8&amp;1\\0&amp;4&amp;1\end{bmatrix}\begin{bmatrix}x\\y\\z\end{bmatrix}=\begin{bmatrix}2\\12\\2\end{bmatrix}$</p><p>消元法的思路：</p><p>$A=\begin{bmatrix}1&amp;2&amp;1\\3&amp;8&amp;1\\0&amp;4&amp;1\end{bmatrix}\underrightarrow{\text{row2-3row1}}\begin{bmatrix}1&amp;2&amp;1\\0&amp;2&amp;-2\\0&amp;4&amp;1\end{bmatrix}\underrightarrow{\text{row3-2row2}}\begin{bmatrix}1&amp;2&amp;1\\0&amp;2&amp;-2\\0&amp;0&amp;5\end{bmatrix}=U$，U的对角线上的元素为三个主元。首先，主元不能为零；其次，如果在消元时遇到主元位置为零，则需要交换行，使主元不为零。当消元失效时，将不能得到三个主元。</p><p>下面进行回代，将矩阵$\begin{bmatrix}A&amp;b\end{bmatrix}$称为增广矩阵。有$\begin{bmatrix}A&amp;b\end{bmatrix}=\begin{bmatrix}1&amp;2&amp;1&amp;2\\3&amp;8&amp;1&amp;12\\0&amp;4&amp;1&amp;2\end{bmatrix}\to\begin{bmatrix}1&amp;2&amp;1&amp;2\\0&amp;2&amp;-2&amp;6\\0&amp;4&amp;1&amp;2\end{bmatrix}\to\begin{bmatrix}1&amp;2&amp;1&amp;2\\0&amp;2&amp;-2&amp;6\\0&amp;0&amp;5&amp;-10\end{bmatrix}$，此时方程组变为$\left\{\begin{aligned}x+2y+z=2\\2y-2z=6\\5z=-10\end{aligned}\right.$，很容易解出$x=2,y=1,z=-2$</p><h1 id="消元矩阵"><a href="#消元矩阵" class="headerlink" title="消元矩阵"></a>消元矩阵</h1><p>下面介绍用行来计算矩阵乘法：</p><script type="math/tex; mode=display">\begin{bmatrix}1&2&7\end{bmatrix}\begin{bmatrix}\cdots&row_1&\cdots\\\cdots&row_2&\cdots\\\cdots&row_3&\cdots\end{bmatrix}=1×row_1+2×row_2+7×row_3</script><p>从矩阵$\begin{bmatrix}1&amp;2&amp;1\\3&amp;8&amp;1\\0&amp;4&amp;1\end{bmatrix}$到矩阵$\begin{bmatrix}1&amp;2&amp;1\\0&amp;2&amp;-2\\0&amp;4&amp;1\end{bmatrix}$是第二行减去3倍的第一行，第一、三行不变，则有</p><script type="math/tex; mode=display">\begin{bmatrix}1&0&0\\-3&1&0\\0&0&1\end{bmatrix}\begin{bmatrix}1&2&1\\3&8&1\\0&4&1\end{bmatrix}=\begin{bmatrix}1&2&1\\0&2&-2\\0&4&1\end{bmatrix}</script><p>将消元矩阵$\begin{bmatrix}1&amp;0&amp;0\-3&amp;1&amp;0\\0&amp;0&amp;1\end{bmatrix}$记作$E_{21}​$，表示第二行第一个元素变为零。同理有</p><script type="math/tex; mode=display">\begin{bmatrix}1&0&0\\0&1&0\\0&-2&1\end{bmatrix}\begin{bmatrix}1&2&1\\0&2&-2\\0&4&1\end{bmatrix}=\begin{bmatrix}1&2&1\\0&2&-2\\0&0&5\end{bmatrix}</script><p>将消元矩阵$\begin{bmatrix}1&amp;0&amp;0\\0&amp;1&amp;0\\0&amp;-2&amp;1\end{bmatrix}$记作$E_{32}$，$E_{21}、E_{32}$都为初等矩阵。将上面两步综合起来有</p><script type="math/tex; mode=display">E_{32}(E_{21}A)=U</script><p>由于矩阵乘法满足结合律，又可以写成</p><script type="math/tex; mode=display">(E_{32}E_{21})A=U</script><p>下面介绍一种用于置换两行或两列的矩阵，称为置换矩阵，例如：</p><script type="math/tex; mode=display">\begin{bmatrix}0&1\\1&0\end{bmatrix}\begin{bmatrix}a&b\\c&d\end{bmatrix}=\begin{bmatrix}c&d\\a&b\end{bmatrix}</script><p>如果交换两列则有</p><script type="math/tex; mode=display">\begin{bmatrix}a&b\\c&d\end{bmatrix}\begin{bmatrix}0&1\\1&0\end{bmatrix}=\begin{bmatrix}b&a\\d&c\end{bmatrix}</script><p>总结：在左边用矩阵做乘法进行的是行变换，在右边用矩阵做乘法进行的是列变换。即列变换时右乘，行变换时左乘。</p><h1 id="逆"><a href="#逆" class="headerlink" title="逆"></a>逆</h1><p>通过消元可以将矩阵$A$变换为$U$，那么将$U$变回$A$的过程称为逆变换。在这里先简单提一下矩阵的逆，这里以$E_{21}$为例：</p><p>$E_{21}$将$A$的第二行减去3倍的第一行，那么其逆变换为第二行加3倍的第一行，所以逆矩阵为$\begin{bmatrix}1&amp;0&amp;0\\3&amp;1&amp;0\\0&amp;0&amp;1\end{bmatrix}$，我们把$E$的逆记作$E^{-1}$，有$E^{-1}E=I$，有</p><script type="math/tex; mode=display">\begin{bmatrix}1&0&0\\3&1&0\\0&0&1\end{bmatrix}\begin{bmatrix}1&0&0\\-3&1&0\\0&0&1\end{bmatrix}=\begin{bmatrix}1&0&0\\0&1&0\\0&0&1\end{bmatrix}</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;消元法&quot;&gt;&lt;a href=&quot;#消元法&quot; class=&quot;headerlink&quot; title=&quot;消元法&quot;&gt;&lt;/a&gt;消元法&lt;/h1&gt;&lt;p&gt;有方程组$\left\{\begin{aligned}x+2y+z=2\\3x+8y+z=12\\4y+z=2\end{aligne
      
    
    </summary>
    
      <category term="线性代数" scheme="http://wuhainan.com/categories/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
    
      <category term="线性代数" scheme="http://wuhainan.com/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>方程组的几何解释</title>
    <link href="http://wuhainan.com/2018/11/12/%E6%96%B9%E7%A8%8B%E7%BB%84%E7%9A%84%E5%87%A0%E4%BD%95%E8%A7%A3%E9%87%8A/"/>
    <id>http://wuhainan.com/2018/11/12/方程组的几何解释/</id>
    <published>2018-11-12T11:21:39.000Z</published>
    <updated>2018-11-14T08:58:56.280Z</updated>
    
    <content type="html"><![CDATA[<p>从一个例子讲起：2个方程，2个未知数的方程组</p><script type="math/tex; mode=display">\left\{\begin{aligned}2x-y=0\\-x+2y=3\\\end{aligned}\right.</script><p>写成矩阵形式为</p><script type="math/tex; mode=display">\begin{bmatrix}2&-1\\-1&2\end{bmatrix}\begin{bmatrix}x\\y\end{bmatrix}=\begin{bmatrix}0\\3\end{bmatrix}</script><p>第一个矩阵称为系数矩阵A，第二个矩阵称为x，第三个矩阵称为b，这样方程组可写为$Ax=b$，一个行图像显示一个方程，可以画出该方程组的行图像：</p><p><img src="/2018/11/12/方程组的几何解释/3.jpg" alt="avatar"></p><p>列图像：</p><p>原方程组可写为$x\begin{bmatrix}2 \\ -1\end{bmatrix}+y\begin{bmatrix}-1\\2\end{bmatrix}=\begin{bmatrix}0\\3\end{bmatrix}$，该方程是寻找如何将$\begin{bmatrix}2 \\ -1\end{bmatrix}$和$\begin{bmatrix}-1\\2\end{bmatrix}$两个向量正确组合，来构成$\begin{bmatrix}0\\3\end{bmatrix}$，这就需要找到正确的线性组合。将$\begin{bmatrix}2 \\ -1\end{bmatrix}$记作$col_1$，$\begin{bmatrix}-1\\2\end{bmatrix}$记作$col_2$，当x=1,y=2时，等式成立。下面画出列向量：</p><p><img src="/2018/11/12/方程组的几何解释/4.png" alt=""></p><p>如果选取所有的x和y，即所有的组合，结果会得到整个二维空间。下面来看三维空间的例子：</p><script type="math/tex; mode=display">\left\{\begin{aligned}2x-y=0\\-x+2y-z=-1\\-3y+4z=4\end{aligned}\right.</script><p>在这里$A=\begin{bmatrix}2&amp;-1&amp;0 \\ -1&amp;2&amp;-1\\0&amp;-3&amp;4\end{bmatrix}，b=\begin{bmatrix}0 \\ -1\\4\end{bmatrix}$。在三维空间中，每一个方程确定一个平面，而例子中的三个平面会相交于一点，这个点就是方程组的解。将方程组写成列向量的线性组合：</p><script type="math/tex; mode=display">x\begin{bmatrix}2\\-1\\0\end{bmatrix}+y\begin{bmatrix}-1\\2\\3\end{bmatrix}+z\begin{bmatrix}0\\-1\\4\end{bmatrix}=\begin{bmatrix}0\\-1\\4\end{bmatrix}</script><p>同样将这三个列向量分别称为$col_1、col_2、col_3$，显而易见，当$x=y=0,z=1$时满足该等式。但不是对于所有的右侧向量$b$都有解，当$col_1、col_2、col_3$共面时，只有当$b$在此平面内时，方程组才有解，否则无解。</p><p>最后介绍矩阵形式的$Ax=b$，举个例子，取$A=\begin{bmatrix}2&amp;5\\1&amp;3\end{bmatrix}，x=\begin{bmatrix}1\\2\end{bmatrix}$，则$Ax=\begin{bmatrix}2&amp;5\\1&amp;3\end{bmatrix}\begin{bmatrix}1\\2\end{bmatrix}=1\begin{bmatrix}2\\1\end{bmatrix}+2\begin{bmatrix}5\\3\end{bmatrix}=\begin{bmatrix}12\\7\end{bmatrix}$</p><p>总之，$A$右侧乘以一个向量可以看成$A$的各列的线性组合。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;从一个例子讲起：2个方程，2个未知数的方程组&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\left\{
\begin{aligned}
2x-y=0\\
-x+2y=3\\
\end{aligned}
\right.&lt;/scrip
      
    
    </summary>
    
      <category term="线性代数" scheme="http://wuhainan.com/categories/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
    
      <category term="线性代数" scheme="http://wuhainan.com/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>朴素贝叶斯</title>
    <link href="http://wuhainan.com/2018/11/08/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
    <id>http://wuhainan.com/2018/11/08/朴素贝叶斯/</id>
    <published>2018-11-08T13:12:19.000Z</published>
    <updated>2018-11-08T13:13:42.758Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>逻辑回归</title>
    <link href="http://wuhainan.com/2018/11/02/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    <id>http://wuhainan.com/2018/11/02/逻辑回归/</id>
    <published>2018-11-02T07:58:20.000Z</published>
    <updated>2018-11-21T00:21:55.119Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="分类" scheme="http://wuhainan.com/tags/%E5%88%86%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>线性模型</title>
    <link href="http://wuhainan.com/2018/10/29/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
    <id>http://wuhainan.com/2018/10/29/线性模型/</id>
    <published>2018-10-29T12:28:35.000Z</published>
    <updated>2018-11-03T00:25:27.723Z</updated>
    
    <content type="html"><![CDATA[<h1 id="线性回归模型"><a href="#线性回归模型" class="headerlink" title="线性回归模型"></a>线性回归模型</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>给定数据集D={$(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),\cdots(x^{(m)},y^{(m)})$}，$x^{(i)}\in\mathcal{X}\subseteq\mathbb{R}^m,y^{(i)}\in\mathcal{Y}\subseteq\mathbb{R},i=1,2,\cdots,m,$其中$x^{(i)}=(x_1^{(i)},x_2^{(i)},\cdots,x_n^{(i)})^T,$m为样本的数量，n为特征的数量。</p><p>线性模型试图学得一个通过属性的线性组合来进行预测的函数，即</p><script type="math/tex; mode=display">f(x)=w_1x_1+w_2x_2+...+w_nx_n+b,</script><p>其中$w$为权重，b为截距，写成向量形式为</p><script type="math/tex; mode=display">f(x)=w^Tx+b</script><p>为了简化公式，设$x^{(i)}=(x_1^{(i)},x_2^{(i)},…x_n^{(i)},1)^T，w=(w_1,w_2,…,w_n,b)^T$，简化之后为</p><script type="math/tex; mode=display">f(x)=\sum_{i=0}^nw_ix_i=w^Tx</script><p>我们的目标便是通过给定的数据集D来学习参数$w$，对于给定的样本$x^{(i)}$，其预测值$\hat{y}^{(i)}=w^Tx^{(i)}$，与真实值$y^{(i)}$越接近越好。这里我们采用平方损失函数，则在训练集D上，模型的损失函数为</p><script type="math/tex; mode=display">L(w)=\sum_{i=1}^m(f(x^{(i)})-y^{(i)})^2\\\quad\quad=\sum_{i=1}^m(w^Tx^{(i)}-y^{(i)})^2</script><p>这样，我们的目标便变为损失函数最小化。为了之后求导方便，在损失函数前乘以1/2，即：</p><script type="math/tex; mode=display">w^*=\mathop{\arg\min}_{w}\frac{1}{2}\sum_{i=1}^m(w^Tx^{(i)}-y^{(i)})^2</script><p>为了求出使$L(w)$最小的$w$值，我们可以使用梯度下降法和正规方程两种方法。</p><h2 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h2><p>梯度下降的思想是：开始时随机选择一个参数的组合$(w_0,w_1,w_2,…,w_n)$，计算损失函数，然后寻找下一个能让损失函数下降最多的参数组合，持续这么做直到一个局部最小值。通常选择不同的初始参数组合，可能会找到不同的局部最小值。</p><p>梯度下降算法公式为：</p><p>重复直到收敛{</p><p>​    $w_j:=w_j-\alpha\frac{\partial}{\partial w_j}L(w)$    </p><p>}</p><p>要实现这个算法，关键在于求出损失函数关于$w$的导数</p><p>$\frac{\partial}{\partial w_j}L(w)=\frac{\partial}{w_j}\frac{1}{2}\sum_{i=1}^m(w^Tx^{(i)}-y^{(i)})^2<br>\\\quad\quad\quad\,\,\,\,=\frac{\partial}{\partial w_j}\frac{1}{2}\sum_{i=1}^m(w_0x_0^{(i)}+w_1x_1^{(i)}+…+w_jx_j^{(i)}+…+w_nx_n^{(i)}-y^{(i)})^2<br>\\\quad\quad\quad\,\,\,\,=2·\frac{1}{2}\sum_{i=1}^m(w_0x_0^{(i)}+w_1x_1^{(i)}+…+w_nx_n^{(i)}-y^{(i)})·x_j^{(i)}<br>\\\quad\quad\quad\,\,\,\,=\sum_{i=1}^m(w^Tx^{(i)}-y^{(i)})x_j^{(i)}$</p><p>重复直到收敛{</p><p>​    $w_j:=w_j+\alpha\sum_{i=1}^m(y^{(i)}-w^Tx^{(i)})x_j^{(i)}​$        (for  every  j)</p><p>}</p><h2 id="正规方程"><a href="#正规方程" class="headerlink" title="正规方程"></a>正规方程</h2><p>正规方程通过求解下面的方程来找出使损失函数最小的参数：$\frac{\partial}{\partial w}L(w)=0$</p><h3 id="矩阵导数"><a href="#矩阵导数" class="headerlink" title="矩阵导数"></a>矩阵导数</h3><p>假设函数$f:R^{m×n}\to R$，从m*n大小的矩阵映射到实数域，那么当矩阵为A时导函数定义如下所示：</p><script type="math/tex; mode=display">\frac{\partial f(A)}{\partial A}=\begin{bmatrix}\frac{\partial f}{\partial A_{11}} & \cdots & \frac{\partial f}{\partial A_{1n}}\\\vdots &\ddots&\vdots\\\frac{\partial f}{\partial A_{m1}}&\cdots&\frac{\partial f}{\partial A_{mn}} \end{bmatrix}</script><p>例如A=$\begin{bmatrix}A_{11}&amp;A_{12}\\A_{21}&amp;A_{22} \end{bmatrix}$是2*2矩阵，给定函数$f:R^{2×2} \to R$为：</p><script type="math/tex; mode=display">f(A)=\frac{3}{2}A_{11}+5A_{12}^2+A_{21}A_{22}</script><p>那么$\frac{\partial f(A)}{\partial A}=\begin{bmatrix}\frac{3}{2}&amp;10A_{12}\\A_{22}&amp;A_{21} \end{bmatrix}$，我们还要引入矩阵的迹(trace)，简写为tr。对于一个给定的n*n的方阵A，它的迹定义为对角线元素之和：</p><script type="math/tex; mode=display">tr\ A=\sum_{i=1}^nA_{ii}</script><p>如果有两矩阵A和B，满足AB为方阵，则迹运算有以下性质：</p><script type="math/tex; mode=display">trAB=trBA\\trABC=trCAB=trBCA\\trA=trA^T\\tr(A+B)=trA+trB\\tr\ aA=atrA</script><p>接下来提出一些矩阵导数：</p><script type="math/tex; mode=display">\frac{\partial(trAB)}{\partial A}=B^T\\\frac{\partial f(A)}{\partial A^T}=(\frac{\partial f(A)}{\partial A})^T\\\frac{\partial(trABA^TC)}{\partial A}=CAB+C^TAB^T\\\frac{\partial |A|}{\partial A}=|A|(A^{-1})^T</script><p>下面把损失函数$L(w)$用向量的形式表述。令</p><script type="math/tex; mode=display">X=\begin{bmatrix}(x^{(1)})^T\\(x^{(2)})^T\\\vdots\\(x^{(m)})^T\end{bmatrix}=\begin{bmatrix}x_1^{(1)}&x_2^{(1)}&\cdots& x_n^{(1)}&1\\x_1^{(2)}&x_2^{(2)}&\cdots&x_n^{(2)}&1\\\vdots&\vdots&\ddots&\vdots&1\\x_1^{(m)}&x_2^{(m)}&\cdots&x_n^{(m)}&1\end{bmatrix}\\y=\begin{bmatrix}y^{(1)}\\y^{(2)}\\\vdots\\y^{(m)}\end{bmatrix},w=\begin{bmatrix}w_1\\w_2\\\vdots\\w_n\\b\end{bmatrix}</script><p>则有</p><script type="math/tex; mode=display">Xw-y=\begin{bmatrix}f(x^{(1)})-y^{(1)}\\f(x^{(2)})-y^{(2)}\\\vdots\\f(x^{(m)})-y^{(m)}\end{bmatrix}\\\frac{1}{2}(Xw-y)^T(Xw-y)=\frac{1}{2}\sum_{i=1}^m(f(x^{(i)})-y^{(i)})^2=L(w)</script><script type="math/tex; mode=display">\begin{equation}\begin{split}\frac{\partial L(w)}{\partial w}&=\frac{\partial }{\partial w}\frac{1}{2}(Xw-y)^T(Xw-y)\\&=\frac{1}{2}\frac{\partial}{\partial w}(w^TX^TXw-w^TX^Ty-y^TXw+y^Ty)\\&=\frac{1}{2}\frac{\partial}{\partial w}tr(w^TX^TXw-w^TX^Ty-y^TXw+y^Ty)\\&=\frac{1}{2}\frac{\partial}{\partial w}(tr(w^TX^TXw)-2tr(y^TXw))\\&=\frac{1}{2}(X^TXw+X^TXw-2X^Ty)\\&=X^TXw-X^Ty\end{split}\end{equation}</script><p>令其等于0便得到下面的正规方程：</p><script type="math/tex; mode=display">X^TXw=X^Ty</script><p>当$X^TX$可逆时，可得：</p><script type="math/tex; mode=display">w^*=(X^TX)^{-1}X^Ty</script><p>于是学得的线性回归模型为：</p><script type="math/tex; mode=display">f(x^{(i)})=w^{*T}x^{(i)}</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;线性回归模型&quot;&gt;&lt;a href=&quot;#线性回归模型&quot; class=&quot;headerlink&quot; title=&quot;线性回归模型&quot;&gt;&lt;/a&gt;线性回归模型&lt;/h1&gt;&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="机器学习" scheme="http://wuhainan.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://wuhainan.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>k-近邻</title>
    <link href="http://wuhainan.com/2018/10/16/k-%E8%BF%91%E9%82%BB/"/>
    <id>http://wuhainan.com/2018/10/16/k-近邻/</id>
    <published>2018-10-16T07:34:15.000Z</published>
    <updated>2018-11-08T13:09:25.879Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>k近邻法是一种基本的分类与回归算法，它的输入为实例的特征向量，通过计算新数据与训练数据特征值之间的距离，然后选取与该实例最邻近的k个实例，这k个实例的多数属于哪一类，就把该输入实例分到这个类。对于分类问题，输出为实例的类别，对于新的实例，根据其k个最近邻的训练实例的类别，通过多数表决等方式进行预测；对于回归问题，输出为实例的值，对于新的实例，取其k个最近邻的训练实例的平均值作为预测值。</p><h1 id="kNN三要素"><a href="#kNN三要素" class="headerlink" title="kNN三要素"></a>kNN三要素</h1><p>k近邻法不具有显式的学习过程，它是直接预测，实际上是利用训练数据集对特征向量空间划分，作为其分类的模型，模型由距离度量、k值的选择、分类决策规则三要素决定。</p><h2 id="距离度量"><a href="#距离度量" class="headerlink" title="距离度量"></a>距离度量</h2><p>特征空间中两个实例点的距离是两个实例点相似程度的反映。k近邻模型的特征空间一般是n维实数向量空间$\mathbb{R}^n$。k近邻模型的特征空间的距离一般使用欧氏距离，也可以是更一般的$L_p$距离。</p><p>设特征空间$\mathcal{X}$是n维实数向量空间，$x_i,x_j\in\mathcal{X},x_i=(x_i^{(1)},x_i^{(2)},\cdots,x_i^{(n)})^T,x_j=(x_j^{(1)},x_j^{(2)},\cdots,x_j^{(n)})^T,x_i,x_j$的$L_p$距离定义为：</p><script type="math/tex; mode=display">L_p(x_i,x_j)=(\sum_{l=1}^n|x_i^{(l)}-x_j^{(l)}|^p)^\frac{1}{p}</script><p>这里$p\ge1$，当$p=2$时，为欧氏距离：</p><script type="math/tex; mode=display">L_2(x_i,x_j)=(\sum_{l=1}^n|x_i^{(l)}-x_j^{(l)}|^2)^\frac{1}{2}</script><p>当$p=1$时，为曼哈顿距离：</p><script type="math/tex; mode=display">L_1(x_i,x_j)=\sum_{l=1}^n|x_i^{(l)}-x_j^{(l)}|</script><p>当$p=\infty$时，为各个维度距离的最大值：</p><script type="math/tex; mode=display">L_\infty(x_i,x_j)=\max_l|x_i^{(l)}-x_j^{(l)}|</script><h2 id="k值的选择"><a href="#k值的选择" class="headerlink" title="k值的选择"></a>k值的选择</h2><p>如果选择较小的k值，相当于用较小的邻域中的训练实例进行预测，“学习”的近似误差会减小，只有与输入实例较近的训练实例才会对预测起作用。但缺点是“学习”的估计误差会增大，预测结果会对近邻的实例点非常敏感。如果邻近的实例点恰巧是噪声，预测就会出错。即k值的减小意味着整体模型变得复杂，容易发生过拟合。</p><p>如果选择较大的k值，相当于用较大的邻域中的训练实例进行预测，其优点是可以减少学习的估计误差。但缺点是学习的近似误差会增大。这时与输入实例较远的训练实例也会对预测起作用，使预测发生错误，即k值的增大意味着整体模型变得简单。当k=N时，无论输入实例是什么，都将简单地预测它为训练实例中最多的类。此时，模型过于简单，完全忽略训练实例中的大量有用信息。</p><p>在应用中，k一般取一个较小的数值。通常采用交叉验证法选取最优的k值，就是比较不同k值时的交叉验证平均误差率，选择误差率最小的那个k值。</p><h2 id="分类决策规则"><a href="#分类决策规则" class="headerlink" title="分类决策规则"></a>分类决策规则</h2><p>k近邻法中的分类决策规则往往是多数表决，即由输入实例的k个近邻的训练实例中的多数类决定输入实例的类，也可以基于距离的远近进行加权投票，距离越近的样本权重越大。</p><p>如果分类的损失函数为0-1损失函数，分类函数为</p><script type="math/tex; mode=display">f：\mathbb{R}^n\to\{c_1,c_2,\cdots,c_K\}</script><p>那么误分类的概率为</p><script type="math/tex; mode=display">P(Y\ne f(X))=1-P(Y=f(X))</script><p>对给定的实例$x\in\mathcal{X}$，其最近邻的k个训练实例点构成集合$N_k(x)$。如果涵盖$N_k(x)$的区域的类别是$c_j$，那么误分类率是</p><script type="math/tex; mode=display">\frac{1}{k}\sum_{x_i\in N_k(x)}I(y_i\ne c_j)=1-\frac{1}{k}\sum_{x_i\in N_k(x)}I(y_i=c_j)</script><p>要使误分类率最小即经验风险最小，就要使$\sum_\limits{x_i\in N_k(x)}I(y_i=c_j)$最大，所以多数表决规则等价于经验风险最化。</p><h1 id="kd树"><a href="#kd树" class="headerlink" title="kd树"></a>kd树</h1><h1 id="sklearn代码"><a href="#sklearn代码" class="headerlink" title="sklearn代码"></a>sklearn代码</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;k近邻法是一种基本的分类与回归算法，它的输入为实例的特征向量，通过计算新数据与训练数据特征值之间的距离，然后选取与该实例最邻近的k个实例，这
      
    
    </summary>
    
      <category term="机器学习" scheme="http://wuhainan.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://wuhainan.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
